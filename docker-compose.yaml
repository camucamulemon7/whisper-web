
services:
  backend:
    image: whisper-backend:latest
    build:
      context: ./backend
      dockerfile: ${DOCKERFILE:-Dockerfile}
    ports:
      - "${API_PORT:-8000}:${API_PORT:-8000}"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_MODULE_LOADING=LAZY
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
      - CUDNN_PATH=/usr/lib/x86_64-linux-gnu
    env_file:
      - .env
    volumes:
      - ./backend:/app
      - whisper-models:/app/models
    command: uvicorn main:app --host ${API_HOST:-0.0.0.0} --port ${API_PORT:-8000} --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${API_PORT:-8000}/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - whisper-network

  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
    env_file:
      - .env
    depends_on:
      - backend
    volumes:
      - ./frontend:/app
      - /app/node_modules
    networks:
      - whisper-network

networks:
  whisper-network:
    driver: bridge

volumes:
  whisper-models:
